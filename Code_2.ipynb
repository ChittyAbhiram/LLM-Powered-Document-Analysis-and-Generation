{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3457d892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain import HuggingFacePipeline, HuggingFaceHub, PromptTemplate, LLMChain\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b24c8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebe2aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEUG_API_TOKEN\"] = \"Your Token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42314cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "article_ulrs = [\"https://www.ibm.com/topics/machine-learning\",\n",
    "                \"https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained\",\n",
    "                \"https://www.ibm.com/topics/neural-networks\",\n",
    "                \"https://www.ibm.com/topics/convolutional-neural-networks\", \n",
    "                \"https://machinelearningmastery.com/what-are-large-language-models/\",\n",
    "                \"https://www.techtarget.com/whatis/definition/support-vector-machine-SVM\",\n",
    "                \"https://www.ibm.com/topics/recurrent-neural-networks\", \n",
    "                \"https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/\",\n",
    "                \"https://machinelearningmastery.com/a-brief-introduction-to-bert/\",\n",
    "                \"https://kaitchup.substack.com/p/a-gentle-introduction-to-gpt-models-e02b093a495b\"\n",
    "               ]\n",
    "\n",
    "loader = WebBaseLoader(article_ulrs)\n",
    "data   = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29a1dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18edb98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishnat/.conda/envs/myenv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "Device has 1 GPUs available. Provide device={deviceId} to `from_model_id` to use availableGPUs for execution. deviceId is -1 (default) for CPU and can be a positive integer associated with CUDA device id.\n",
      "/home/krishnat/.conda/envs/myenv/lib/python3.10/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      "/home/krishnat/.conda/envs/myenv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\nAnswer:\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = HuggingFacePipeline.from_model_id(model_id=\"facebook/opt-125m\",\n",
    "                                        task=\"text-generation\", \n",
    "                                        model_kwargs={\"temperature\": 0, \"max_length\": 2048})\n",
    "\n",
    "index = VectorstoreIndexCreator(embedding = HuggingFaceEmbeddings()).from_loaders([loader])\n",
    "index.query(\"What is answering system?\", llm=llm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf8d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44b10a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 50)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54138aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b8d968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insert of existing embedding ID: 160\n",
      "Insert of existing embedding ID: 161\n",
      "Insert of existing embedding ID: 162\n",
      "Insert of existing embedding ID: 163\n",
      "Insert of existing embedding ID: 164\n",
      "Insert of existing embedding ID: 165\n",
      "Insert of existing embedding ID: 166\n",
      "Insert of existing embedding ID: 167\n",
      "Insert of existing embedding ID: 168\n",
      "Insert of existing embedding ID: 169\n",
      "Insert of existing embedding ID: 170\n",
      "Insert of existing embedding ID: 171\n",
      "Insert of existing embedding ID: 172\n",
      "Insert of existing embedding ID: 173\n",
      "Insert of existing embedding ID: 174\n",
      "Insert of existing embedding ID: 175\n",
      "Insert of existing embedding ID: 176\n",
      "Insert of existing embedding ID: 177\n",
      "Insert of existing embedding ID: 178\n",
      "Insert of existing embedding ID: 179\n",
      "Insert of existing embedding ID: 180\n",
      "Insert of existing embedding ID: 181\n",
      "Insert of existing embedding ID: 182\n",
      "Insert of existing embedding ID: 183\n",
      "Insert of existing embedding ID: 184\n",
      "Insert of existing embedding ID: 185\n",
      "Insert of existing embedding ID: 186\n",
      "Insert of existing embedding ID: 187\n"
     ]
    }
   ],
   "source": [
    "def batch(docs, b_size=100):\n",
    "    length = len(docs)\n",
    "    for num in range(0, length, b_size):\n",
    "        yield docs[num:min(num+b_size, length)]\n",
    "\n",
    "ids_prev = 0\n",
    "vectorstore = ''\n",
    "full_ids = [str(i) for i in range(0, len(all_splits) + 1)]\n",
    "\n",
    "for b in batch(all_splits, 160):\n",
    "    ids = [str(i) for i in range(ids_prev, (len(b) + ids_prev), 1)]\n",
    "    ids_prev += len(ids)\n",
    "    vectorstore_initial = Chroma.from_documents(documents=b, embedding=HuggingFaceEmbeddings(),ids=ids)\n",
    "    if not vectorstore:\n",
    "        vectorstore = vectorstore_initial\n",
    "    else:\n",
    "        vec = vectorstore_initial._collection.get(ids=ids)\n",
    "        vectorstore._collection.add(documents=vec['documents'], embeddings=vec['embeddings'], \n",
    "                                    metadatas=vec['metadatas'], ids=vec['ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf125538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6d6c8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188'])\n"
     ]
    }
   ],
   "source": [
    "to_cluster = {}\n",
    "\n",
    "for id in full_ids:\n",
    "    temp_vec = vectorstore._collection.get(ids=[full_ids[int(id)]],include=['embeddings'])\n",
    "    to_cluster[id] = temp_vec['embeddings']\n",
    "\n",
    "print(to_cluster.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5744b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6e9b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(data, k):\n",
    "    np.random.seed(12345)\n",
    "    rand_init = np.random.choice(len(data), k, replace=False)\n",
    "    centroids = {}\n",
    "    dists = {}\n",
    "    same = True\n",
    "    for i in range(k):\n",
    "        centroids[i] = data[rand_init[i]]\n",
    "    while same == True:\n",
    "        for i in range(len(data)):\n",
    "            cntr_arr = []\n",
    "            for key in centroids:\n",
    "                cntr_arr.append(math.dist(data[i],centroids[key]))\n",
    "            dists[i] = cntr_arr\n",
    "       \n",
    "        groupID = {}\n",
    "        for key, value in enumerate(dists):\n",
    "            groups = {}\n",
    "            grouping = dists[key].index(min(dists[key]))\n",
    "            groups[key] = [data[key]]\n",
    "            if groupID.get(grouping) is not None:\n",
    "                groupID[grouping].append(groups)\n",
    "            else:\n",
    "                groupID[grouping] = [groups]\n",
    "        oldcentr = centroids\n",
    "        for i in range(k):\n",
    "            centroids[i] = np.sum(np.vstack([list(groupID[i][j].values())[0][0] for j in range(len(groupID[i]))]), \n",
    "                                  axis=0)/len(groupID[i])\n",
    "        if centroids == oldcentr:\n",
    "            same = False\n",
    "    return groups, groupID, centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7a8d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = to_cluster.values()\n",
    "arrayData = list(values)\n",
    "\n",
    "newray = []\n",
    "for i in range(len(arrayData)-1):\n",
    "    newray.append(arrayData[i][0])\n",
    "array = np.array(list(newray))\n",
    "k=10\n",
    "np.random.seed(1234)\n",
    "groups, groupID, centroids = kmeans(array, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b523169d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "303b530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_centroid = {}\n",
    "for i in range(len(groupID)):\n",
    "    for j in groupID[i]:\n",
    "        emb_dist = {}\n",
    "        emb_dist[list(j.items())[0][0]] = [math.dist(list(j.values())[0][0],centroids[i])]\n",
    "        if rep_centroid.get(i) is not None:\n",
    "            rep_centroid[i].append(emb_dist)\n",
    "        else:\n",
    "            rep_centroid[i] = [emb_dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7af2e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d474998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {133: 0.45277704980530126}, 1: {40: 0.5141776415263648}, 2: {78: 0.5933098983677147}, 3: {160: 0.5331631567225045}, 4: {51: 0.4995249203541028}, 5: {169: 0.6587031175758578}, 6: {73: 0.5842050937326108}, 7: {186: 0.0}, 8: {62: 0.5503525579043758}, 9: {89: 0.6165880000536104}}\n"
     ]
    }
   ],
   "source": [
    "mins = {}\n",
    "for key, value in enumerate(rep_centroid):\n",
    "    current_min = 999\n",
    "    current_id = 0\n",
    "    min_dict = {}\n",
    "    for keyi, vali in enumerate(rep_centroid[key]):\n",
    "        new_val = list(rep_centroid[key][keyi].values())[0][0]\n",
    "        new_id = list(rep_centroid[key][keyi].items())[0][0]\n",
    "        if new_val < current_min:\n",
    "            current_min = new_val\n",
    "            current_id = new_id\n",
    "    min_dict[current_id] = current_min\n",
    "    mins[key] = min_dict\n",
    "\n",
    "print(mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aabc070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffd82026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A recurrent neural network (RNN) is a type of artificial neural network which uses sequential data or time series data. These deep learning algorithms are commonly used for ordinal or temporal problems, such as language translation, natural language processing (nlp), speech recognition, and image captioning; they are incorporated into popular applications such as Siri, voice search, and Google Translate. Like feedforward and convolutional neural networks (CNNs), recurrent neural networks utilize training data to learn. They are distinguished by their “memory” as they take information from prior inputs to influence the current input and output. While traditional deep neural networks assume that inputs and outputs are independent of each other, the output of recurrent neural networks depend on the prior elements within the sequence. While future events would also be helpful in determining the output of a given sequence, unidirectional recurrent neural networks cannot account for these', 'With the growing ubiquity of machine learning, everyone in business is likely to encounter it and will need some working knowledge about this field. A 2020 Deloitte survey found that 67% of companies are using machine learning, and 97% are using or planning to use it in the next year.\\nFrom manufacturing to retail and banking to bakeries, even legacy companies are using machine learning to unlock new value or boost efficiency. “Machine learning is changing, or will change, every industry, and leaders need to understand the basic principles, the potential, and the limitations,” said MIT computer science professor Aleksander Madry, director of the MIT Center for Deployable Machine Learning.\\nWhile not everyone needs to know the technical details, they should understand what the technology does and what it can and cannot do, Madry added. “I don’t think anyone can afford not to be aware of what’s happening.”', '𝐶𝑜𝑠𝑡 𝐹𝑢𝑛𝑐𝑡𝑖𝑜𝑛= 𝑀𝑆𝐸=1/2𝑚 ∑129_(𝑖=1)^𝑚▒(𝑦\\xa0̂^((𝑖) )−𝑦^((𝑖) ) )^2\\nUltimately, the goal is to minimize our cost function to ensure correctness of fit for any given observation. As the model adjusts its weights and bias, it uses the cost function and reinforcement learning to reach the point of convergence, or the local minimum. The process in which the algorithm adjusts its weights is through gradient descent, allowing the model to determine the direction to take to reduce errors (or minimize the cost function). With each training example, the parameters of the model adjust to gradually converge at the minimum.\\xa0\\xa0\\nSee this IBM Developer article for a deeper explanation of the quantitative concepts involved in neural networks.', 'Rostlab researchers show language models trained without labeled samples picking up the signal of a protein sequence.\\nThe OpenAI lab showed bigger is better with its Generative Pretrained Transformer (GPT). The latest version, GPT-3, has 175 billion parameters, up from 1.5 billion for GPT-2.\\nWith the extra heft, GPT-3 can respond to a user’s query even on tasks it was not specifically trained to handle. It’s already being used by companies including Cisco, IBM and Salesforce.\\nTale of a Mega Transformer\\nNVIDIA and Microsoft hit a high watermark in November, announcing the Megatron-Turing Natural Language Generation model (MT-NLG) with 530 billion parameters. It debuted along with a new framework, NVIDIA NeMo Megatron, that aims to let any business create its own billion- or trillion-parameter transformers to power custom chatbots, personal assistants and other AI applications that understand language.', 'Neural networks\\nNeural networks are a commonly used, specific class of machine learning algorithms. Artificial neural networks are modeled on the human brain, in which thousands or millions of processing nodes are interconnected and organized into layers.\\nIn an artificial neural network, cells, or nodes, are connected, with each cell processing inputs and producing an output that is sent to other neurons. Labeled data moves through the nodes, or cells, with each cell performing a different function. In a neural network trained to identify whether a picture contains a cat or not, the different nodes would assess the information and arrive at an output that indicates whether a picture features a cat.\\nDeep learning', 'USA - United States\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tNVIDIA websites use cookies to deliver and improve the website experience. See our cookie policy for further details on how we use cookies and how to change your cookie settings.\\t\\t\\t\\nACCEPT\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n \\n\\xa0Share This\\xa0Facebook\\xa0LinkedIn\\xa0Email', 'Let’s break down what one single node might look like using binary values. We can apply this concept to a more tangible example, like whether you should go surfing (Yes: 1, No: 0). The decision to go or not to go is our predicted outcome, or y-hat. Let’s assume that there are three factors influencing your decision-making:', 'Start WritingGet the appSubstack is the home for great writing', 'In some cases, machine learning models create or exacerbate social problems. For example, Facebook has used machine learning as a tool to show users ads and content that will interest and engage them —\\xa0which has led to models showing people extreme content that leads to polarization and the spread of conspiracy theories when people are shown incendiary, partisan, or inaccurate content.\\nWays to fight against bias in machine learning including carefully vetting training data\\xa0and putting organizational support behind ethical artificial intelligence efforts, like making sure your organization embraces human-centered AI, the practice of seeking input from people of different backgrounds, experiences, and lifestyles when designing AI systems. Initiatives working on this issue include the Algorithmic Justice League and\\xa0The Moral Machine\\xa0project.\\nPutting machine learning to work', 'What are Convolutional Neural Networks?  | IBM\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    \\n\\n\\n\\n  \\n    What are convolutional neural networks?\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                \\n\\n                        \\n\\n\\n  \\n  \\n      Learn how convolutional neural networks use three-dimensional data to for image classification and object recognition tasks\\n  \\n\\n\\n\\n\\n    \\n\\n\\n                    \\n\\n\\n\\nDiscover watsonx.ai\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\n    What are convolutional neural networks?']\n"
     ]
    }
   ],
   "source": [
    "cent_docs = []\n",
    "for i in range(k):\n",
    "    cent_docs.append(vectorstore._collection.get(ids=str(list(mins[i].items())[0][0]),\n",
    "                                                 include=['documents'])['documents'][0])\n",
    "print(cent_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27533ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6084f826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")\n",
    "\n",
    "def get_paraphrased_sentences(model, tokenizer, sentence, num_return_sequences=10, num_beams=10):\n",
    "    inputs = tokenizer([sentence], truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, num_beams=num_beams, num_return_sequences=num_return_sequences)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750d2bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a93c1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishnat/.conda/envs/myenv/lib/python3.10/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 is paraphrased as:  ['A recurrent neural network (RNN) is a type of artificial neural network that', 'A recurrent neural network (RNN) is a type of artificial neural network which', 'Recurrent neural networks (RNNs) are a type of artificial neural network that uses', 'The recurrent neural network (RNN) is a type of artificial neural network that', 'A recurrent neural network (RNN) is a type of artificial neural network using', 'Recurrent neural networks (RNNs) are a type of artificial neural network which uses', 'Unlike feedforward and convolutional neural networks (CNNs), recurrent neural', 'Like feedforward and convolutional neural networks (CNNs), recurrent neural networks', 'A recurrent neural network (RNN) is a kind of artificial neural network that', 'A recurrent neural network (RNN) is a type of artificial neural network ']\n",
      "Document 1 is paraphrased as:  ['With the growing ubiquity of machine learning, everyone in business is likely to encounter it', 'A 2020 Deloitte survey found that 67% of companies are using machine learning and', 'With the increasing ubiquity of machine learning, everyone in business is likely to encounter it', 'With the growing ubiquity of machine learning, everyone in the business is likely to encounter', 'With the growing ubiquity of machine learning, everyone is likely to encounter it and will', 'With the growing ubiquity of machine learning, everyone in business is likely to encounter and', 'A 2020 Deloitte survey found that 67% of businesses are using machine learning and', 'With the growing ubiquity of machine learning, everyone in business is likely to encounter', 'With the growing ubiquity of machine learning, everyone in business is likely to face it', 'In 2020, a Deloitte survey found that 67% of companies are using']\n",
      "Document 2 is paraphrased as:  ['Cost Function= MSE=1/2m 129_(i=1)m', 'Cost function= MSE=1/2m 129_(i=1)m', 'Cost Function = MSE=1/2m 129_(i=1)m', 'Cost function = MSE=1/2m 129_(i=1)m', 'As the model adjusts its weights and biases, it uses the cost function and', 'The goal is to minimize the cost function to ensure the correctness of fit for any given observation', 'As the model adjusts its weights and biases, it uses the cost function', 'The goal is ultimately to minimize our cost function to ensure correctness of fit for any given observation', 'The goal is to minimize our cost function to ensure correctness of fit for any given observation ', 'The goal is to minimize the cost function to ensure correctness of fit for any given observation ']\n",
      "Document 3 is paraphrased as:  ['The OpenAI lab showed language models trained without labeled samples picking up the signal of ', 'Rostlab researchers show language models trained without labeled samples picking up the signal of ', 'Rostlab researchers show language models trained without labeled samples pick up the signal of ', 'The OpenAI lab showed language models trained without labeled samples that pick up the signal of', 'Rostlab researchers show language models trained without labeled samples that pick up the signal of', 'The Rostlab researchers show language models trained without labeled samples picking up the signal of', 'In November, Rostlab researchers showed language models trained without labeled samples picking up the', 'The OpenAI lab showed that language models trained without labeled samples pick up the signal of', 'The Rostlab researchers showed language models trained without labeled samples picking up the signal of', 'In November, the OpenAI lab showed language models trained without labeled samples picking up the']\n",
      "Document 4 is paraphrased as:  ['Neural networks Neural networks are a commonly used, specific class of machine learning algorithms ', 'Neural networks Neural networks are a commonly used class of machine learning algorithms modeled on', 'Neural networks Neural networks are a common, specific class of machine learning algorithms modeled', 'Neural networks Neural networks are a common class of machine learning algorithms modeled on the', 'Neural networks Neural networks are a commonly used class of machine learning algorithms based on', 'Artificial neural networks Neural networks are a commonly used, specific class of machine learning algorithms ', 'Neural networks Neural networks are a widely used, specific class of machine learning algorithms ', 'Neural networks Neural networks are modeled on the human brain in which thousands or millions of', 'Artificial neural networks Neural networks are a commonly used class of machine learning algorithms modeled on', 'Neural networks Neural networks are a commonly used class of machine learning algorithms that are ']\n",
      "Document 5 is paraphrased as:  ['USA - United States NVIDIA websites use cookies to deliver and improve the website experience.', 'NVIDIA websites use cookies to deliver and improve the website experience. See our cookie policy for', 'USA - United States NVIDIA websites use cookies to deliver and improve the website experience ', 'US - United States NVIDIA websites use cookies to deliver and improve the website experience.', 'NVIDIA websites use cookies to deliver and improve the website experience. See our Cookie Policy for', 'USA - United States NVIDIA websites use cookies to deliver and improve the website experience See', 'NVIDIA websites use cookies to deliver and improve the website experience. See our cookie policy', 'US - United States NVIDIA websites use cookies to deliver and improve the website experience ', 'NVIDIA websites use cookies to deliver and improve the website experience. See our cookies policy for', 'NVIDIA websites use cookies to deliver and improve the website experience. See our Cookie Policy']\n",
      "Document 6 is paraphrased as:  ['Let’s break down what a single node might look like using binary values,', 'Let’s break down what a single node might look like using binary values.', 'Let’s break down what a single node might look like using binary values. We', 'Let’s break down what a single node might look like using binary values, like', 'Let’s break down using binary values what a single node might look like (Yes', 'Let’s break down what a single node might look like using binary values and apply', 'Let’s break down what a single node might look like using binary values (Yes', 'Let’s break down what one single node might look like using binary values, like', 'Let’s break down what a single node might look like using binary values –', 'Let’s break down what one single node might look like using binary values. We']\n",
      "Document 7 is paraphrased as:  ['Start writingGet the appSubstack is the home for great writing', 'Start WritingGet the appSubstack is the home for great writing', 'Start writingGet the appSubstack is the home for great writing.', 'Start WritingGet the appSubstack is the home for great writing.', 'Start writingGet the appSubstack is the home for great writing.', 'Start WritingGet the appSubstack is the home for great writing.', 'Start writingGet the appSubstack is the home of great writing', 'Start WritingGet the appSubstack is the home of great writing', 'Substack is the home for great writingGet the appSubstack is the', 'Start WritingGet the app Substack is the home for great writing']\n",
      "Document 8 is paraphrased as:  ['In some cases, machine learning models create or exacerbate social problems. For example, Facebook', 'In some cases, machine learning models create or exacerbate social problems — for example, Facebook', 'For example, Facebook has used machine learning as a tool to show users ads and content that', 'In some cases, machine learning models create or exacerbate social problems. For example,', 'In some cases, machine learning models create or exacerbate social problems. For example, Facebook has', 'For example, Facebook has used machine learning as a tool to show ads and content that will', 'In some cases, machine learning models create or exacerbate social problems — for example,', 'Machine learning models create or exacerbate social problems in some cases. For example, Facebook has', 'In some cases, machine learning models create or exacerbate social problems : for example, Facebook', 'In some cases, machine learning models create or exacerbate social problems. For example,']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 9 is paraphrased as:  ['What are convolutional neural networks? | IBM Learn how convolutional neural networks use three', 'What are convolutional neural networks? | IBM What are convolutional neural networks Learn how', 'What are convolutional neural networks? | IBM What are convolutional neural networks? Learn', 'What are Convolutional Neural Networks? | IBM Learn how convolutional neural networks', 'Learn how convolutional neural networks use three-dimensional data for image classification and object recognition tasks', 'What are Convolutional Neural Networks? | IBM What are convolutional neural networks', 'What are Convolutional Neural Networks? | IBM What are Convolutional Neural', 'What are Convolutional Neural Networks? | IBM Learn how Convolutional Neural', '| IBM What are convolutional neural networks? Learn how convolutional neural networks use three', 'Learn how convolutional neural networks use three-dimensional data to perform image classification and object recognition']\n"
     ]
    }
   ],
   "source": [
    "for document in range(k):\n",
    "    sentence = get_paraphrased_sentences(model, tokenizer, cent_docs[document], num_beams=10, num_return_sequences=10)\n",
    "    print(\"Document\" , document, \"is paraphrased as: \", sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8a7cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d54778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4e7536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
